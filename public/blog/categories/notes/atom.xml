<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Notes | liwanag]]></title>
  <link href="http://neauro.github.io/liwanag/blog/categories/notes/atom.xml" rel="self"/>
  <link href="http://neauro.github.io/liwanag/"/>
  <updated>2013-12-19T21:34:06-08:00</updated>
  <id>http://neauro.github.io/liwanag/</id>
  <author>
    <name><![CDATA[nadine a.]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Notes From Messing Around With Processing Tutorials]]></title>
    <link href="http://neauro.github.io/liwanag/blog/2011/06/08/notes-from-messing-around-with/"/>
    <updated>2011-06-08T00:00:00-07:00</updated>
    <id>http://neauro.github.io/liwanag/blog/2011/06/08/notes-from-messing-around-with</id>
    <content type="html"><![CDATA[<div class='post'>
<table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-RhK-RFQbcGY/TfBC8WD0qyI/AAAAAAAAAQk/pllWCnFCrLM/s1600/processingcircles.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="319" src="http://4.bp.blogspot.com/-RhK-RFQbcGY/TfBC8WD0qyI/AAAAAAAAAQk/pllWCnFCrLM/s320/processingcircles.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">my first great processing creation</td></tr></tbody></table><br />Processing is apparently supposed to allow artists to interface with Java as if it were more of a scripting language, in case Java itself is too scary or complicated.  (It's also meant to allow you to do simple projects without the overhead of all the Java code and learning Java, and is a good gateway programming language.)  Actually, thinking about it now, my first project with Java involving drawing a house, lifting pens and putting them down and changing colors and all.  It was the most frustrating thing ever and I'm glad I stuck with CS anyway.<br /><br />Little bundles of code for Processing are referred to as "sketches." Here is the code in case you want to create a sketch to make tons of circles for yourself.  (It is also Tutorial 1 on the Processing website.)<br /><br /><pre class="brush:jscript">void setup() {<br />  size(480, 120);<br />  smooth();<br />}<br /><br />void draw() {<br />  if (mousePressed) {<br />    fill(0);<br />  } else {<br />    fill(255);<br />  }<br />  ellipse(mouseX, mouseY, 80, 80);<br />}<br /></pre><br />It seems that <code>setup()</code> is called once, when the program starts running; <code>draw()</code> is called constantly, much like an <code>update()</code> function in game programming.  You can also name functions with headers like <code>void mousePressed()</code>, which is a function which would be called every time the mouse is pressed.<br /><br />After you're done coding something with Processing, you can Export it into an applet, or an application for Windows, OSX, or Linux.  You can also just easily save frames by calling <code>saveFrame("name-of-output-picture####.png")</code>, where the hash marks will be replaced with a numbered sequence.<br /><br />Here's sample code that deals with creating a Car object in Processing:<br /><br /><pre class="brush:jscript">Car myCar1;<br />Car myCar2; // Two objects!<br /><br />void setup() {<br />  size(200,200);<br />  // Parameters go inside the parentheses when the object is constructed.<br />  myCar1 = new Car(color(255,0,0),0,100,2); <br />  myCar2 = new Car(color(0,0,255),0,10,1);<br />}<br /><br />void draw() {<br />  background(255);<br />  myCar1.drive();<br />  myCar1.display();<br />  myCar2.drive();<br />  myCar2.display();<br />}<br /><br />// Even though there are multiple objects, we still only need one class. <br />// No matter how many cookies we make, only one cookie cutter is needed.<br />class Car { <br />  color c;<br />  float xpos;<br />  float ypos;<br />  float xspeed;<br /><br />  // The Constructor is defined with arguments.<br />  Car(color tempC, float tempXpos, float tempYpos, float tempXspeed) { <br />    c = tempC;<br />    xpos = tempXpos;<br />    ypos = tempYpos;<br />    xspeed = tempXspeed;<br />  }<br /><br />  void display() {<br />    stroke(0);<br />    fill(c);<br />    rectMode(CENTER);<br />    rect(xpos,ypos,20,10);<br />  }<br /><br />  void drive() {<br />    xpos = xpos + xspeed;<br />    if (xpos &gt; width) {<br />      xpos = 0;<br />    }<br />  }<br />}<br /></pre><br />And here's an example of grabbing samples of color from an image:<br /><pre class="brush:jscript">for (int x = 0; x &lt; img.width; x++) {<br />  for (int y = 0; y &lt; img.height; y++ ) {<br />    // Calculate the 1D pixel location<br />    int loc = x + y*img.width;<br />    // Get the R,G,B values from image<br />    float r = red   (img.pixels[loc]);<br />    float g = green (img.pixels[loc]);<br />    float b = blue  (img.pixels[loc]);<br />    // Change brightness according to the mouse here<br />    float adjustBrightness = ((float) mouseX / width) * 8.0;<br />    r *= adjustBrightness;<br />    g *= adjustBrightness;<br />    b *= adjustBrightness;<br />    // Constrain RGB to between 0-255<br />    r = constrain(r,0,255);<br />    g = constrain(g,0,255);<br />    b = constrain(b,0,255);<br />    // Make a new color and set pixel in the window<br />    color c = color(r,g,b);<br />    pixels[loc] = c;<br />  }<br />}<br /></pre>Other miscellaneous notes: <br /><ul><li><code>width</code> and <code>height</code> are variables which refer to the size of the sketch</li><li><code>size(x, y, option)</code> will create a sketch of width x and height y, with an optional rendering mode.  The default is <code>JAVA2D</code>, which does high-quality 2D graphics at the expense of speed.  <code>P2D</code> refers to Processing 2D, which has simple graphics and fast pixel operations, so it's good if you need to do thousands of shapes.  <code>P3D</code> (Processing 3D renderer) can produce 3D graphics even without the use of a library, and is meant for speed and pixel operations.  <code>OPENGL</code> mixes use of Sun's Java for OpenGL library for faster rendering, and Processing's APIs for application export (for which the <code>P3D</code> renderer is a simpler solution, if you don't want your users to see the whole "Are you sure you want to trust Sun Microsystems" dialog).  Finally, <code>size(x, y, PDF, "pdf-name.pdf")</code> will draw to a file rather than a screen.</li><li>You can load images easily in Processing, but it takes a while, so it's best to do it only once; i.e. not in <code>draw()</code> but in <code>setup()</code>.<br /></li></ul><br /><br />Sources: <br /><ul><li><a href="http://processing.org/learning/gettingstarted/">Processing: Getting Started</a></li><li><a href="http://processing.org/learning/overview/">Processing: Processing Overview</a></li><li><a href="http://processing.org/learning/objects/">Processing: Object Oriented Programming</a></li><li><a href="http://processing.org/learning/pixels/">Processing: Images &amp; Pixels</a></li></ul></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating Systems: System Calls and I/O]]></title>
    <link href="http://neauro.github.io/liwanag/blog/2011/03/04/operating-systems-system-calls-and-io/"/>
    <updated>2011-03-04T00:00:00-08:00</updated>
    <id>http://neauro.github.io/liwanag/blog/2011/03/04/operating-systems-system-calls-and-io</id>
    <content type="html"><![CDATA[<div class='post'>
Okay so, applications go through the operating system to obtain data from the disk, using system calls.  There are a couple types of system calls.<br /><br />When an application makes a <strong>blocking system call</strong>, the application stops executing, and moves into the operating system's wait queue.  When the system call completes, the application gets placed back to the run queue, and when it's ready to execute, it gets the response back from the completed system call.  Most operating systems use blocking system calls because blocking application code is easier to understand.<br /><br />But some user-side processes need non-blocking I/O and so make <strong>non-blocking system calls</strong>, a good example of which are human-interface devices: i.e. the mouse, the keyboard.  Input has to be taken and used, and can't be delayed until later.  When an operating system supports non-blocking system calls, a call doesn't stop execution of the application, but rather returns quickly, indicating how much data that it was able to read immediately.<br /><br />One way that a programmer can deal with overlapping execution of code and I/O is to write a multi-threaded application, so that some threads can do blocking system calls while others execute code.<br /><br />An alternative to non-blocking system calls are <strong>asynchronous system calls</strong>, which also return immediately, and allow the application to continue executing code.  Later, when the I/O finishes, the application is notified via some shared variable or a call-back routine or an interrupt.  The main difference is that with a non-blocking system call, the immediate return contains whatever data it was able to read immediately, whereas an asynchronous system call will eventually finish reading everything it was supposed to and return that data later.</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating Systems: File Systems, Journaling File Systems]]></title>
    <link href="http://neauro.github.io/liwanag/blog/2011/03/04/operating-systems-file-systems/"/>
    <updated>2011-03-04T00:00:00-08:00</updated>
    <id>http://neauro.github.io/liwanag/blog/2011/03/04/operating-systems-file-systems</id>
    <content type="html"><![CDATA[<div class='post'>
It's Thursday night/Friday morning, which means it's time to cram-study for the OS quiz tomorrow!  <span class="shh">This cram session brought to you by coke obtained at a Rails party at Joshu's place.</span><br /><br /><br /><span class="sig">File Systems</span><br />So we've most recently gone over file system stuff, <a href="http://nuubu.blogspot.com/2011/02/operating-system-notes-fat-file-system.html">a little bit</a> of which I've talked about (mostly FAT file systems.)<br /><br />File system in general have a couple simple roles:<ul><li>they implement an abstraction (files/directories) for storage of data</li><li>they logically organize files (i.e. into a hierarchy of directories)</li><li>they allow people to share data (in terms of access control, consistency)</li></ul><br />A <strong>file</strong> is basically just a collection of data which also has certain properties (i.e. size, owner, last modified date, etc.) Files also have "types" which allow them to be understood by the file system or by other programs -- i.e., a file can be a .txt, or an .exe, or a directory, which is actually just a generic "file" which contains a list of other files.  Types are encoded in a file's extension.<br /><br />Some file systems allow applications to access data in different ways -- i.e. sequentially (reading bytes one at a time), or by direct access (giving the application a block/byte number), or by indexed access (like a database), etc.<br /><br />Given some path name, like <code>C:\one\two\three</code>, the file system will access that folder first by opening <code>C:</code>, then searching for <code>one\</code>, then opening <code>one\</code>, then searching for <code>two\</code>, then opening <code>two\</code>...basically the file system spends a lot of time walking down directory paths, which is why "open" is usually a separate function from "read/write."  To make directory crawling go faster, the file system will cache some prefix lookups, like <code>C:\Windows</code>.<br /><br />File systems also have the happy job of implementing a protection system for its files, either by controlling who can access a file, or by controlling by whom a file is accessed.  Some models for representing protection are<ul><li><strong>access control lists (ACLs)</strong>, in which each object knows what user can do what with it, and</li><li><strong>capabilities</strong>, in which each user knows what they can do with each object.</li></ul><br />Capabilities can be handed off, which makes sharing easier; but ACLs are easier to manage, since you can just have a file and say, "This is system32, <em>no one write to this ever</em>."  ACLs can grow pretty large when an object is heavily shared between a lot of users, though they can be simplified by categorizing the users into "groups" (i.e. an object knows it can be altered by admins, but only read by normal users).<br /><br /><br /><span class="sig">Disks</span><br />So the file system goes on top of the disk, which has all dat memorys.  Disks are always divided into five parts:<ol><li>boot block, which contains information to boot the system</li><li>superblock, which specified boundaries of next areas and contains head of freelists of inodes and file blocks</li><li>i-node area, which contains descriptors for each file on disk</li><li>file contents area, the head of which is in the super-block, and the</li><li>swap area, which holds processes which have been swapped out of memory.</li></ol><br />An i-node is a data structure traditional to a Unix-style file system, and basically stores all the information about a regular file, directory, or file system object, other than its data and name.  Each file in a file system correspondes to one i-node.  I-nodes also contain a "block list," in the form of 13 block pointers, 10 of which are "direct pointers" to a block of data corresponding to a file.  The last 3 are pointers to pointers.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-_-IcQmBgdJQ/TXCzs3P_nAI/AAAAAAAAAJU/1kKKk4i5l4E/s1600/inodes.jpg" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="174" width="320" src="http://1.bp.blogspot.com/-_-IcQmBgdJQ/TXCzs3P_nAI/AAAAAAAAAJU/1kKKk4i5l4E/s320/inodes.jpg" /></a></div><br />I-nodes and file blocks are both cached in memory, only forced to be written to disk when the command "sync" is called by the operating system (every couple seconds).  If the computer crashes or has a power failure (i.e. you get frustrated with your computer and do a hard reset), you can have an inconsistent disk.  So, avoid hard resets!<br /><br />To make sure flat file systems are consistent, ask yourself: Does each block belong precisely to one file, or else is it free?  If you're looking at the consistency of a directory structure, do all the directories form a tree, and do the number of inodes equal the number of directories you'll find if you start crawling through all of them?<br /><br /><br /><br /><span class="sig">Journaling File Systems</span><br />So in light of the fact that crashes can and probably will happen when something is being written to disk, how do you make sure stuff stays consistent?  Here is where OS takes a lot of ideas from databases, specifically, atomicity and logs.  <strong>Atomicity</strong> is when you ensure that an action/set of actions are executed completely and perfectly, or else not at all.  <strong>Logs</strong> are a record of the actions that you've done to date.<br /><br /><strong>Journaling file systems</strong> are a special (yet dated to the 80s) type of file system which takes a advantage of redo logs.  The general idea is:<ul><li>always have a "home copy" of your data in a consistent/up-to-date state</li><li>make updates persistent by writing them in order to a "journal" partition or file on disk</li><li>at your leisure, push updates to the home copies to free up space in the journal</li><li>make sure that you've written a record of your action to your log before updating the disk</li></ul><br />Once an action/transaction has been "committed" to the log, you know for sure that you want it on disk.  So, if you crash, recover your log and redo all of the actions that you did there.  This fixes the problem that you might have committed something -- i.e. intended to write it to the disk -- but ran into a problem before you were actually able to write to disk.  Redo logs are the easiest type of log to implement.  <br /><br />Once you've got a log of your "committed" data, you can have another thread walk through it and flush items to disk.  Once an item has been flushed, it can be deleted from the log.<br /><br />The problem with the log is that it's one, big contiguous write -- so though it's efficient, it is another I/O, so it's really costly performance-wise.  Thus, journaling file systems can improve performance and make recovery really efficient, but isn't worth it in a really busy system.<br /><br /><br /><br />Sources:<br />lecture 14 notes<br />Wikipedia: <a href="http://en.wikipedia.org/wiki/I-node">inode</a></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating Systems Notes [Disk Caching, RAID Levels, Flash Memory)]]></title>
    <link href="http://neauro.github.io/liwanag/blog/2011/02/17/operating-systems-notes-disk-caching/"/>
    <updated>2011-02-17T00:00:00-08:00</updated>
    <id>http://neauro.github.io/liwanag/blog/2011/02/17/operating-systems-notes-disk-caching</id>
    <content type="html"><![CDATA[<div class='post'>
This is a quick rehash of what we've learned in the previous week!<br /><br /><span class="sig">Disk Caching</span><br />So the OS can optimize operations done by scheduling things, either <a href="http://nuubu.blogspot.com/2011/01/operating-systems-notes-chapter-5-cpu.html">CPU</a> or <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">memory</a>.  The operating system can also schedule disk operations, which are reads/writes from/to the disk (that far-off entity which stores the data you want, yet is time-consuming and expensive to reach).<br /><br /><strong>Disk scheduling</strong> is optimized especially through <strong>disk caching</strong>.  Disk caching can come in two flavors.  <strong>Write caching</strong> is when the user has the data that they want to write to disk, and the OS, rather than writing that data directly to the disk, instead writes it to a cache.  Then, sometime later, the OS writes everything in the cache to the disk.  There's a sort of "five minute rule" to this, where (very roughly) every "five minutes or so," the cache gets "flushed" to disk.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-wDujboA5CPU/TV4Ffh_w4XI/AAAAAAAAAHs/qyHyYUHJcPs/s1600/writecaching.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="81" src="http://3.bp.blogspot.com/-wDujboA5CPU/TV4Ffh_w4XI/AAAAAAAAAHs/qyHyYUHJcPs/s320/writecaching.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">our TA's lecture notes are so cool</td></tr></tbody></table><br />There's also <strong>read caching</strong>, which is when the operating system reads data from the disk into a cache, so as to be easily and quickly accessed by the user later.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-6A1WwUsxBH8/TV4FjpY-ETI/AAAAAAAAAH0/UahzFruaJtY/s1600/readcaching.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="83" src="http://1.bp.blogspot.com/-6A1WwUsxBH8/TV4FjpY-ETI/AAAAAAAAAH0/UahzFruaJtY/s320/readcaching.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">look at this. &nbsp;just look how understandable this is</td></tr></tbody></table><br /><br />One way to take advantage of disk caching is to use <strong>memory mapped I/O</strong>.  The data in a disk cache exists in kernel space, so what's an easy way for a process in user-space to get a hold of it?  To have the process contain a mapping directly to that disk cache!<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-OU-tACxsM5Q/TV4GYm7X0jI/AAAAAAAAAH8/BQaW5asqgME/s1600/memorymappedio.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="126" src="http://2.bp.blogspot.com/-OU-tACxsM5Q/TV4GYm7X0jI/AAAAAAAAAH8/BQaW5asqgME/s320/memorymappedio.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">these colors are just so neat</td></tr></tbody></table><br />The segment of a process's <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">virtual address</a> which has been mapped is called a <strong>memory-mapped file</strong>; in this case, it's the blue part.<br /><br />As the process uses the file, it may need to write to it, which means eventually that the pages that the user-space process altered will need to be flushed to disk, or written out to disk.  The OS will know which pages to write thanks to the alteration of a dirty bit.  When the ditry bit is high, that means that the page has been altered and will need to be flushed.  <span class="shh">(Somehow this whole paragraph feels a little gross...)</span><br /><br /><br /><span class="sig">RAID Levels</span><br />are another thing that we've been talking about in lecture.  The thing about disks in general is that though they are a pretty useful/necessary storage device for computers, they're super messy -- they run into errors all the time, like bad blocks, or missed seeks.  Part of the job of the operating system is to hide all this messy-ness from higher-level software (i.e. software that other, more sane programmers will write to be run on the computer).  The OS will provide different levels of access to different clients -- for instance, allowing them to access physical disk blocks (a specific head, or cylinder of the disk) or just logical disk blocks (i.e. a program says "I want disk 6" and the OS retrieves the real location of "disk 6" itself).<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-pZ8QGur6iSg/TV4MPA-H3hI/AAAAAAAAAIE/Sv47rFhynK0/s1600/harddrive.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="223" src="http://4.bp.blogspot.com/-pZ8QGur6iSg/TV4MPA-H3hI/AAAAAAAAAIE/Sv47rFhynK0/s320/harddrive.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">this is what a disk looks like, by the way</td></tr></tbody></table><br />It takes time for an OS to find something on a disk.  The performance is based on three main things:<br /><ol><li><strong>Seeking</strong>: how long it takes to move the disk arm to the correct cylinder on the disk</li><li><strong>Rotation</strong>: how long it takes to wait for the sector you want to rotate under the head of the reader.  This depends on the rotation rate of the disk, which is not increasing that quickly, mainly because the way disks are made now, if they spin any faster they'll fall apart</li><li><strong>Transfer</strong>: how long it takes to transfer data from the surface of the disk into the disk controller, and from there back to the process that wants the data</li></ol><br />The OS mainly tries to reduce seek times and rotation.<br /><br />So, since disk transfer rates in general are improving, and since CPU performance isn't, what you can do to improve performance is have multiple disks containing/transferring data.  In particular, you can "stripe" files across multiple disks by placing parts of each file on a different disk, making it so that you can read parts of a file simultaneously (i.e. use <strong>parallel I/O</strong> to read a single file).<br /><br />The problem with striping is that it's not very reliable.  To improve its reliability, you can add redundant data to the disks, along with striping, and thus -- <strong>RAID: Redundant Array of Inexpensive Disks</strong>.  Since disks are physically small and cheap, you can just stick a lot of them into one box to increase storage, performance, and availability.  Depending on how you stripe data, you can affect resulting performance and reliability in different ways.<br /><br />What are some things to consider in different methods of striping?  Firstly, <strong>granularity</strong>.  If you stripe each file across multiple disks ("fine-grained" granularity), you will get high throughput for reading the file, but limit overall transfer to one file at a time.  If you stripe each file over only a few disks ("coarse-grained" granularity), you limit throughput for 1 file, but can have concurrent access to multiple files.<br /><br />Another thing to think about is the <strong>redundancy</strong> itself.  If you uniformly distribute redundancy, then you'll avoid load-balancing problems.  You can also concentrate redundancy information on a subset of your total disks, and make it so that some of your total disks are "data disks" and the others are "redundancy disks."<br /><br />So what are the different types of RAID?<br /><br /><strong>RAID Level 0</strong> is when you have a non-redundant disk array -- files are just striped across disks, with no redundant info saved at all.  There's high read throughput (since you can do the parallel I/O thing), and also high write throughput (since you don't need to write redundant info).  However, if one of your disks fails, then you can lose the file and sometimes the entire volume, which is horrible. D: D:<br /><br /><strong>RAID Level 1</strong> is also known as "mirrored disks." Files are striped across half the disks, and when you write data, it gets written to both a "data disk" and the "mirror disks," which are copies of the data disk.  This way, if the data disks fail, you can just use the surviving disks.  A downside to this technique is that you need to have 2N the amount of space to hold N amount of data, understandably.<br /><br /><strong>RAID Level 2, 3, 4</strong> all pretty much have the same idea, I guess -- they all use error correcting code (ECC) or <strong>parity disks</strong> to provide fault tolerance.  Each byte on a parity disks is a parity function of the corresponding bytes on all the other disks.  This way, a read accesses all data disks.  A write accesses all data disks, as well as the parity disk.  If the disk fails, read what you have of the file and then use the parity disk to compute the missing data.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-hxvTkkUW3Bs/TV4N-F5JUiI/AAAAAAAAAIM/CHZ7y8sofE0/s1600/parity%2Bdrives.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="105" src="http://2.bp.blogspot.com/-hxvTkkUW3Bs/TV4N-F5JUiI/AAAAAAAAAIM/CHZ7y8sofE0/s320/parity%2Bdrives.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">yeah! &nbsp;go parity drive, go!</td></tr></tbody></table><br />But, <strong>what is parity, again?</strong> I guess, given a byte, you want to add a bit set so that the total number of 1's in the byte is even; that way, any single missing bit can be reconstructed.  Parity bites are used as the simplest form of error detecting.<br /><br /><strong>RAID Level 5</strong> uses <strong>block interleaved distributed parity</strong>, which is just like the parity scheme of earlier RAIDs, but instead of having one parity disk, the parity info is distributed across all disks.  For each block, one disk holds the parity, and the other disks hold the data.  This type of RAID has significantly better performance, since the parity disk is not a hot spot.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-MwfHA3qWfcQ/TV4O_26wZlI/AAAAAAAAAIU/FyZ1f6cnCsA/s1600/raid5.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="150" src="http://4.bp.blogspot.com/-MwfHA3qWfcQ/TV4O_26wZlI/AAAAAAAAAIU/FyZ1f6cnCsA/s320/raid5.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">RAID Level 5 disk layout</td></tr></tbody></table><br />So when you use RAID, you can also use a <strong>RAID controller</strong>, which is embedded in the hardware.  A RAID controller can make it seem to the OS like the many disks you're using is actually just one disk.<br /><br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-gvTCVSUmMAU/TV4PdUh6pbI/AAAAAAAAAIc/qiESnTQW4-M/s1600/raidcontroller.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="135" src="http://4.bp.blogspot.com/-gvTCVSUmMAU/TV4PdUh6pbI/AAAAAAAAAIc/qiESnTQW4-M/s320/raidcontroller.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">"What's that? &nbsp;I only have one disk? &nbsp;Oh, cool"</td></tr></tbody></table><br />The advantages of putting <em>policy</em> in the RAID controller is that it makes the OS's job easier.  The disadvantage is that every time you put a layer of abstraction into something, you ruin the chance of optimizing it.  So, putting this layer of abstraction makes the OS a little simpler to program, but now you can't optimize the OS (like, using disk scheduling effectively) the way you could if the OS <em>did</em> have control of and was aware of all of its assets.<br /><br /><br /><span class="sig">Solid State Disks (Flash)</span><br />We also talked about flash drives, which was pretty interesting.  Like disks, the data on a flash drive is stored in blocks.  Since there aren't any spinning platters, random access is fast, and you don't need disk scheduling algorithms.  It's very fast to read from a flash drive thanks to the random access, but slower to write to a flash drive, because the flash media must be erased before it can be written to.  So, when you're writing to a solid state drive like a flash drive, you're actually a) reading some block, b) erasing that block, c) writing back the modified block.  But, there are ways of "hiding the warts of an SSD" (as these section notes put it), mostly by virtualizing pages and blocks on the drive (so you're working with logical pages, not physical pages), and doing "wear-leveling," which is when you try to spread our the erasure of blocks evenly over the drive.<br /><br />Meanwhile, what is a solid-state drive?  Evidently it's just a data storage device toat uses solid-state memory to store persistent data.  "Solid-state" refers to a type of electronics which are build entirely from solid materials, within which electrons or other charge carriers are confined within the solid material.  Solid-state memory I think is like RAM, which gets erased once you shut down your computer, but as of 2010, most solid-state drives use NAND-based flash memory, which can hold memory even if there's no power running through it.  "NAND flash" just refers to the way that the transistors are hooked up in the flash drive: in a way that resembles a NAND gate.<br /><br />Sources:<br />section 7 notes<br /><a href="http://en.wikipedia.org/wiki/Memory-mapped_file">Wikipedia: Memory-mapped file</a>, <a href="http://en.wikipedia.org/wiki/Parity_disk">Parity Drive</a>, <a href="http://en.wikipedia.org/wiki/Parity_bit">Parity bit</a>, <a href="http://en.wikipedia.org/wiki/Solid_state_drive">Solid-state drive</a>, <a href="http://en.wikipedia.org/wiki/Solid-state_(electronics)">Solid state (electronics)</a>, <a href="http://en.wikipedia.org/wiki/Flash_memory#NAND_flash">NAND flash</a><br />lecture 12 notes ("Disk")<br />lecture 13 notes ("Raid and Volumes")</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Operating Systems Notes [Virtual Memory, Page Tables, TLBs]]]></title>
    <link href="http://neauro.github.io/liwanag/blog/2011/02/11/operating-systems-notes-virtual-memory/"/>
    <updated>2011-02-11T00:00:00-08:00</updated>
    <id>http://neauro.github.io/liwanag/blog/2011/02/11/operating-systems-notes-virtual-memory</id>
    <content type="html"><![CDATA[<div class='post'>
So in case <a href="http://nuubu.blogspot.com/2011/02/operating-systems-notes-memory.html">it wasn't clear already</a>, <a href="http://en.wikipedia.org/wiki/Virtual_memory">virtual memory</a> is a memory management technique which accomplishes these things:<ul><li>hides fragmentation of physical memory from programs</li><li>uses hardware memory more efficiently than systems without virtual memory</li><li>lets a program be designed as though there's only one hardware memory (rather than one memory split up between different processes, I think?)</li></ul><br />An important aspect of implementing virtual memory is page tables.  A page table translates a program's virtual address (used to refer to a function or variable or whatnot) into a physical address (which is the actual location of that function's code data, or the variable's value data).  Page tables make it so that programs can only be partially loaded into memory.  <strong>So, what happens when a program tries to access a part of its code which isn't loaded into memory?<br /><br />A PAGE FAULT.</strong><br /><br />When a page fault happens,<ol><li>the OS is given an <a href="http://nuubu.blogspot.com/2011/01/operating-system-notes-chapter-1.html">interrupt</a></li><li>the OS saves the state of the running process, then searches (in the appropriate vector) for the page fault handler routine)</li><li>the page fault handler routine will find or create (through eviction) a page frame into which to load the page that the program needs</li><li>then it will find that page on the disk and place it into the now-free page frame</li><li>then it will fix up the page table entry -- marking it "valid," setting the "referenced" and "modified" bits to false, setting the pointers properly</li><li>finally, the process is placed back into the ready queue</li></ol><br />Anyway, it's getting late and I want to go to bed so for now I'll just skip to<br /><br /><br /><span class="sig">Translation Lookaside Buffers (TLBs)</span><br />to whom we must extend our gratitude for not making page tables awful.  Think about it: if you have a virtual address and you need to look into the page table and then into the physical address in order to actually obtain some value, that's a <em>lot</em> of overhead.<br /><br />To make this more efficient, you want to make fetching from a virtual address just about as efficient as fetching from a physical address.  Which you can do with an extra piece of hardware, a cache inside the CPU.<br /><br />Thus, virtual-to-physical translations are cached in the hardware itself, the TLB.  The TLB translates virtual page numbers into page frame numbers (<em>not physical addresses</em>), and can do it in a single machine cycle.  The TLB in turn is managed by the memory management unit (MMU), which is what calculates the physical address from the page table entry and an offset.<br /><br />TLBs exploit the fact that processes have good temporal locality and spatial locality.  This is a fancy way of saying that processes tend to<ul><li>use data/code they have recently used</li><li>use data/code that is close to data/code they have recently used</li></ul>Which is why <em>caching</em>, or saving that data in an easily accessible place (as you may cache your potato chips, water bottles, and chocolate beneath the bedside  table) is a good idea.<br /><br />So, the TLB does the translation between virtual addresses and page frame numbers, and when it misses -- when it can't find a page frame number -- the translation is saved into the TLB by the OS.<br /><br />In order for TLBs to work, the OS must make sure the TLB and page tables are consistent and up-to-date, and <strong>when a context switch happens, the TLB must be completely flushed</strong>, which means that context switching is still an expensive operation -- all those cached translations, that optimization, disappears.  (The TLB needs to be flushed rather than saved and loaded with the rest of the process state because there's no guarantee that other processes wouldn't mess around with the data the TLB was keeping track of, and to keep the TLB up-to-date when it isn't being presently used by a process is expensive.)<br /><br /><br /><br />Sources:<br /><a href="http://en.wikipedia.org/wiki/Virtual_memory">Wikipedia: Virtual memory</a><br />lecture 11a notes</div>

]]></content>
  </entry>
  
</feed>
