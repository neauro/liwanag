---
layout: post
title: "Operating Systems Notes [Chapter 6: Process Synchronization]"
date: 2011-01-18
comments: false
categories:
 - operating systems
 - notes
 - compsci
---

<div class='post'>
So a <strong>cooperating process</strong> is one that can affect or be affected by other processes, because it shares address space (code, data) with other processes, or because it can share data through passing messages or files.  But, if you share data, then you can run into inconsistencies, i.e. if I'm reading a paper of numbers, adding them up, and halfway down while I'm reading it someone starts changing stuff.  By the time I get to the end of the paper, the answer that I get won't properly reflect the sum of numbers that had originally been on the paper.<br /><br />The situation in which the outcome of the execution depends on the order of things that take place is a <strong>race condition</strong>.  So, the example earlier is a race condition, because the outcome will be different if I a) read and sum the paper, and then the paper gets rewritten, or if b) someone rewrites the paper, and then I read and sum the paper's contents.<br /><br /><strong>Process synchronization</strong> concerns itself with making sure that the changes that result from different processes don't interfere with what other processes are doing, even if they're all sharing the same <strike>paper</strike> set of data.<br /><br />Parts of code to especially watch out for when trying to synchronize things are those parts that modify or write things, i.e. changing variables, outputting to file.  The part of a process which does this is called the <strong>critical section</strong> and to ensure consistency, you want to be sure you have critical sections which fulfill the following requirements:<ul><li><strong>mutual exclusion:</strong> only one thread is executing in the critical section at any time</li><li><strong>progress:</strong> if thread A and thread B are both outside of the critical section, neither can prevent the other from entering the critical section</li><li><strong>bounded waiting:</strong> (i.e. no starvation) if thread A is waiting to enter the critical section, it will enter it eventually</li><li><strong>performance:</strong> entering and exiting the critical section is small compared to the amount of work being done within it</li></ul><br />Critical sections can be built with <a href="http://nuubu.blogspot.com/2011/01/q-semaphore-mutex.html">semaphores and locks</a>, as well as monitors and messages.  Messages are when processes communicate to each other and have their synchronization taken care of through a communication layer; this is particularly important to <a href="http://nuubu.blogspot.com/2011/01/remote-procedure-calls-rpc.html">RPCs</a> in distributed systems.  Monitors are an abstract data structure which I talk more about below.<br /><br />Locks are the lowest-level mechanism you can use, and are really primitive.  Locks can be implemented either as spin-locks, which is when a process which needs a lock acquires it and goes; but if the lock is already posessed by another thread, the process will sit in a while loop, "spinning," until the lock is free.  This is actually pretty bad because you're using up CPU doing nothing, just...spinning around.<br /><br />You can also implement locks by disabling interrupts, and making sure that some process which is currently executing will not be interfered with by any other process.  But only the kernel should be able to disable interrupts, and if you have long periods of no interruptions then you can "wreak havoc" on certain devices.<br /><br />Both spinlocks and disabling interrupts should only be used to build higher-level constructs to ensure proper synchronization of processes.<br /><br /><br />Anyway, kernels can also run into race conditions.  For example, the kernel has a data structure that keeps track of all files that are presently open, and a race condition will occur if two processes open files simultaneously.  To handle critical sections in operating systems, there are <strong>preemptive kernels</strong> (which allow a process to be interrupted in kernel mode), and <strong>nonpreemptive kernels</strong> (which do not allow a process running in kernel mode to be preempted/interrupted, meaning a running kernel-mode process will run until it exits kernel mode).  Preemptive kernels, despite being prone to race conditions, are good for real-time programming scenarios, and are also more responsive since there's less of a chance that you'll have to wait for some arbitrary period until the processor is free to take on another process.<br /><br /><br /><span class="sig">Monitors</span><br />A monitor is an abstract data type which defines a set of operations which are allowed to be mutually exclusive.  It's basically a class that allows shared private data, methods, and automatic synchronization.  A procedure defined in the monitor can only affect variables declared in the monitor, and variables defined in the monitor can only be accessed by functions in the monitor.  Within the monitor, only one process runs at a time.<br /><br />Monitors rely on a <strong>condition variable</strong>, which does three things:<ol><li><code>wait</code> -- release a lock, wait for a signal, recapture a lock</li><li><code>signal</code> -- wake up at most one thread which is waiting to access shared resource</li><li><code>broadcast</code> -- wake up all waiting threads</li></ol>Monitors also manage queues of processes which are waiting to access the shared resource.<br /><br />A monitor can fix deadlocks in the dining philosophers problem.  A monitor would sit in the middle of the dining table, and the philosopher would first ask the monitor for forks.  The monitor would then make a couple of checks on the environment, see if there were any forks <strike>in the queue</strike> available, and if there is a good amount, then the monitor tell his pet condition construct, "Let the philosopher eat!"  The philosopher would then obtain forks, eat, and talk to the monitor again when he or she is done eating.<br /><br />There are two types of monitors: Hoare monitors, and Mesa monitors (the latter being the most prevalent today).  They differ in what action happens in the waiting queue after the condition variable signals.  In Hoare monitors, the waiting process is run immediately after <code>signal</code> is called, because it indicates that a resource that the process want has been freed.  In Mesa monitors, the signal doesn't mean that a resource has been freed, rather only that something has changed.  Thus, when signal happens, the waiter is made ready to go, but only runs when the shared resource is completely for sure available.<br /><br />Unfortunately for monitors, they're pretty heavyweight, so you can't do any "fine-grained locking" -- you have one thread in the monitor at a time, and that's it.<br /><br /><br />Sources:<br /><em>Operating System Concepts (8th Edition)</em>, Silberschatz, Galvin and Gagne, ISBN 978-0-470-12872-5.<br /><a href="http://en.wikipedia.org/wiki/Atomicity">Wikipedia: Atomicity</a><br />lecture notes<br />section TA's intensely well-designed slides</div>
